{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import SparsePCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB,GaussianNB\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,f1_score,make_scorer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import ShuffleSplit,cross_val_score"
      ],
      "metadata": {
        "id": "kxv_iVbAoHNp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Train data\n",
        "with open(\"/content/drive/MyDrive/Train.txt\", \"r\") as tr:\n",
        "    Train = tr.readlines()\n",
        "#read Test data\n",
        "with open(\"/content/drive/MyDrive/Test.txt\", \"r\") as te:\n",
        "    Test = te.readlines()\n",
        "print (len(Train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP5oqigbb200",
        "outputId": "fcab565d-50ff-4cf7-b64c-e06c58ec7e5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_active = []\n",
        "train_features = []\n",
        "test_features = []\n",
        "\n",
        "\n",
        "for i in range(len(Train)):\n",
        "    lines = Train[i]\n",
        "    for l in range(len(lines)):\n",
        "        if l == 1:\n",
        "            drug_active.append(lines[0:1])\n",
        "\n",
        "#Split the train dataset features into list\n",
        "for features in Train:       \n",
        "    features = features.replace(\"0\\t\", \"\")\n",
        "    features = features.replace(\"1\\t\", \"\")\n",
        "    features = features.replace(\"\\n\", \"\")\n",
        "    features = features.split()       \n",
        "    train_features.append(features)\n",
        "\n",
        "#Split the test dataset features into list\n",
        "for features in Test:       \n",
        "    features = features.replace(\"0\\t\", \"\")\n",
        "    features = features.replace(\"1\\t\", \"\")\n",
        "    features = features.replace(\"\\n\", \"\")\n",
        "    features = features.split()       \n",
        "    test_features.append(features)\n",
        "\n",
        "print(len(train_features))\n",
        "print(len(test_features))\n",
        "print(len(drug_active))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYvo-pNndFnN",
        "outputId": "6a1d04b0-99ef-4c73-b58f-f9a261f856ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "350\n",
            "800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sparse = []\n",
        "total_features_count = 100001\n",
        "\n",
        "for features in train_features:\n",
        "  train_sparse_set = [0]*total_features_count\n",
        "  for feature in features:\n",
        "    train_sparse_set[int(feature)] = 1\n",
        "  train_sparse.append(train_sparse_set)\n",
        "\n",
        "test_sparse = []\n",
        "\n",
        "for features in test_features:\n",
        "  test_sparse_set = [0]*total_features_count\n",
        "  for feature in features:\n",
        "    test_sparse_set[int(feature)] = 1\n",
        "  test_sparse.append(test_sparse_set)\n",
        "\n",
        "print(len(train_sparse[0]))\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_sparse,drug_active,test_size=0.20,random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BbxgHAvVTTO",
        "outputId": "40d60b8f-ef6c-401d-f3ba-ba7d2c185068"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chi2_selection = SelectKBest(chi2, k=300)\n",
        "train_sparse_1=chi2_selection.fit_transform(x_train,y_train)\n",
        "test_sparse_1 = chi2_selection.transform(x_test)\n",
        "train_sparse_final=chi2_selection.fit_transform(train_sparse,drug_active)\n",
        "test_sparse_final = chi2_selection.transform(test_sparse)\n",
        "print(train_sparse_1.shape)\n",
        "print(test_sparse_1.shape)"
      ],
      "metadata": {
        "id": "0HTTZ1sopUPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6304bef-81da-4a80-e4b1-5c4c6d8fe2c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 300)\n",
            "(160, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote_sm = SMOTE(random_state = 42)\n",
        "train_sparse_sm_1,drug_active_sm_1 = smote_sm.fit_resample(train_sparse_final,drug_active)\n",
        "train_sparse_sm,drug_active_sm = smote_sm.fit_resample(x_train,y_train)\n",
        "print(len(train_sparse_sm))\n",
        "print(len(train_sparse_sm[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZlALl9VMCjw",
        "outputId": "076998bb-3bbb-46fa-e42b-aaf562627c48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1152\n",
            "100001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svd = TruncatedSVD(n_components=350)\n",
        "svd1 = TruncatedSVD(n_components=350)\n",
        "\n",
        "pca1 = PCA(n_components = 0.95)\n",
        "sparse_train_svd = svd1.fit_transform(train_sparse,drug_active)\n",
        "train_svd1 =  svd1.transform(x_train)\n",
        "test_svd1 = svd1.transform(x_test)\n",
        "sparse_test_svd = svd1.transform(test_sparse)\n",
        "\n",
        "sparse_train_pca = pca1.fit_transform(train_sparse,drug_active)\n",
        "train_pca1 =  pca1.transform(x_train)\n",
        "test_pca1 = pca1.transform(x_test)\n",
        "sparse_test_pca = pca1.transform(test_sparse)\n",
        "\n",
        "\n",
        "sparse_svd = svd.fit_transform(train_sparse_sm,drug_active_sm)\n",
        "pca = PCA(n_components = 0.95)\n",
        "sparse_pca = pca.fit_transform(train_sparse_sm)\n",
        "\n",
        "\n",
        "train_svd = svd.transform(x_train)\n",
        "#print(train_svd)\n",
        "train_pca = pca.transform(x_train)\n",
        "print(train_pca)\n",
        "\n",
        "\n",
        "test_svd = svd.transform(x_test)\n",
        "#print(test_svd)\n",
        "test_pca = pca.transform(x_test)\n",
        "#print(test_pca)\n",
        "\n",
        "test_sparse_svd = svd.transform(test_sparse)\n",
        "test_sparse_pca = pca.transform(test_sparse)\n",
        "\n",
        "#print(sparse_svd.shape)\n",
        "print(train_svd.shape)\n",
        "print(test_svd.shape)\n",
        "print(test_sparse_svd.shape)\n",
        "#print(test_sparse_svd.shape)\n",
        "#print(sparse_pca.shape)\n",
        "#print(train_pca.shape)\n",
        "#print(test_pca.shape)\n",
        "#print(test_sparse_pca.shape)\n",
        "print(svd.explained_variance_ratio_.sum())\n",
        "print(svd1.explained_variance_ratio_.sum())"
      ],
      "metadata": {
        "id": "zw3jrSO13vkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a57532-46f1-4006-8789-8e40f9fef7f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.86343415 -0.9389797  -1.8621428  ... -0.07786184 -1.40887876\n",
            "   0.27059813]\n",
            " [ 0.23559506 -0.46630539 -1.99946801 ...  1.12678214  0.73971695\n",
            "  -0.70937452]\n",
            " [ 0.22928774 -0.56249729 -1.77969048 ...  0.07219735 -0.47950398\n",
            "  -0.16373381]\n",
            " ...\n",
            " [ 0.49479459 -0.65691126 -2.31260623 ...  0.50008196  0.43206119\n",
            "   1.51974749]\n",
            " [ 1.56153352 -1.6991631  -1.38846366 ...  0.72498023  0.69248242\n",
            "  -0.28803238]\n",
            " [ 0.25934995 -0.33730987 -2.44705785 ...  0.59846312 -0.20847595\n",
            "   0.25736581]]\n",
            "(640, 350)\n",
            "(160, 350)\n",
            "(350, 350)\n",
            "0.6364965222143759\n",
            "0.552302639357118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model=DecisionTreeClassifier()\n",
        "grid_params={'criterion':['gini','entropy'],'min_samples_split':[2,3,4,5,6,7,8]}\n",
        "grid=GridSearchCV(dt_model,grid_params,cv=5,scoring='f1_macro')\n",
        "grid.fit(train_pca,y_train)"
      ],
      "metadata": {
        "id": "IAePivVgK5ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a380ef8f-329c-4854-9c5c-9ab330fcf3e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8]},\n",
              "             scoring='f1_macro')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model1=DecisionTreeClassifier()\n",
        "grid_params={'criterion':['gini','entropy'],'min_samples_split':[2,3,4,5,6,7,8]}\n",
        "grid1=GridSearchCV(dt_model1,grid_params,cv=5,scoring='f1_macro')\n",
        "grid1.fit(train_svd,y_train)"
      ],
      "metadata": {
        "id": "z8IJeeyrcggE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9278e047-b053-45b9-bee0-6bc00b936fd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8]},\n",
              "             scoring='f1_macro')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best score is: \",grid.best_score_)\n",
        "print(\"The best Parameters are: \",grid.best_params_)\n",
        "print(\"The best score is: \",grid1.best_score_)\n",
        "print(\"The best Parameters are: \",grid1.best_params_)"
      ],
      "metadata": {
        "id": "g21-hed9DZeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757337cf-93f2-4100-f329-8f0eca612f3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best score is:  0.7446101632018353\n",
            "The best Parameters are:  {'criterion': 'entropy', 'min_samples_split': 2}\n",
            "The best score is:  0.7396086483824178\n",
            "The best Parameters are:  {'criterion': 'gini', 'min_samples_split': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive = BernoulliNB() \n",
        "naive.fit(train_pca,y_train)\n",
        "naive_pred=naive.predict(test_pca)\n",
        "naive_acc=accuracy_score(y_test,naive_pred)*100\n",
        "print(\"The training accuracy for decision tree model is: \",naive_acc)\n",
        "print(classification_report(y_test,naive_pred))"
      ],
      "metadata": {
        "id": "7Fr5yPKK4hQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0948ea9-9c06-44f7-af7e-75dbb3425901"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy for decision tree model is:  96.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       146\n",
            "           1       0.90      0.64      0.75        14\n",
            "\n",
            "    accuracy                           0.96       160\n",
            "   macro avg       0.93      0.82      0.86       160\n",
            "weighted avg       0.96      0.96      0.96       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive1 = BernoulliNB() \n",
        "naive1.fit(train_svd,y_train)\n",
        "naive_pred1=naive1.predict(test_svd)\n",
        "naive_acc1=accuracy_score(y_test,naive_pred1)*100\n",
        "print(\"The training accuracy for decision tree model is: \",naive_acc1)\n",
        "print(classification_report(y_test,naive_pred1))"
      ],
      "metadata": {
        "id": "bK-p7RLO5JJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b4cf84-5e99-424c-abe4-68b1e2e650d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy for decision tree model is:  96.25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       146\n",
            "           1       0.83      0.71      0.77        14\n",
            "\n",
            "    accuracy                           0.96       160\n",
            "   macro avg       0.90      0.85      0.87       160\n",
            "weighted avg       0.96      0.96      0.96       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_1 = GaussianNB()\n",
        "naive_1.fit(train_svd,y_train)\n",
        "naive_pred2=naive_1.predict(test_svd)\n",
        "naive_acc_1=accuracy_score(y_test,naive_pred2)*100\n",
        "print(\"The training accuracy for decision tree model is: \",naive_acc_1)\n",
        "print(classification_report(y_test,naive_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08fN8ibXTbl7",
        "outputId": "c8f45643-f491-4931-f810-92f5f9cb7e2e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy for decision tree model is:  91.875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       146\n",
            "           1       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           0.92       160\n",
            "   macro avg       0.96      0.54      0.55       160\n",
            "weighted avg       0.93      0.92      0.89       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_test_final=naive.predict(test_sparse_pca)\n",
        "dt_test_final1=naive1.predict(test_sparse_svd)\n",
        "dt_test_final_1=naive_1.predict(test_sparse_svd)"
      ],
      "metadata": {
        "id": "l0_9TqJ05WaI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model=DecisionTreeClassifier(criterion='entropy',min_samples_split=8)\n",
        "dt_model.fit(train_pca,y_train)\n",
        "dt_train_pred=dt_model.predict(test_pca)\n",
        "dt_acc=accuracy_score(y_test,dt_train_pred)*100\n",
        "print(\"The training accuracy for decision tree model is: \",dt_acc)\n",
        "print(classification_report(y_test,dt_train_pred))"
      ],
      "metadata": {
        "id": "Z4dtErIAEtOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6596a2-a9bf-4b24-cbdf-83142f431095"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy for decision tree model is:  94.375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       146\n",
            "           1       0.69      0.64      0.67        14\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.83      0.81      0.82       160\n",
            "weighted avg       0.94      0.94      0.94       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model1=DecisionTreeClassifier(criterion='gini',min_samples_split=4)\n",
        "print(train_svd.shape)\n",
        "print(test_svd.shape)\n",
        "dt_model1.fit(train_svd,y_train)\n",
        "dt_train_pred1=dt_model1.predict(test_svd)\n",
        "dt_acc=accuracy_score(y_test,dt_train_pred)*100\n",
        "print(\"The training accuracy for decision tree model is: \",dt_acc)\n",
        "print(classification_report(y_test,dt_train_pred1))"
      ],
      "metadata": {
        "id": "Z5hYRJf8gX5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2252884-71f9-491a-c888-5c20d76930e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 350)\n",
            "(160, 350)\n",
            "The training accuracy for decision tree model is:  94.375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97       146\n",
            "           1       1.00      0.29      0.44        14\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.97      0.64      0.71       160\n",
            "weighted avg       0.94      0.94      0.92       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_test_pred=dt_model.predict(test_sparse_pca)\n",
        "dt_test_pred1=dt_model1.predict(test_sparse_svd)"
      ],
      "metadata": {
        "id": "B2OaA8F3P2KZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"HW2_Result3.txt\", \"w\") as f:\n",
        "    for s in dt_test_pred:\n",
        "        f.write(str(s) +\"\\n\")\n",
        "\n",
        "with open(\"HW2_Result4.txt\", \"w\") as f:\n",
        "    for s in dt_test_pred1:\n",
        "        f.write(str(s) +\"\\n\")\n",
        "\n",
        "with open(\"HW2_Result2.txt\", \"w\") as f:\n",
        "    for s in dt_test_final:\n",
        "        f.write(str(s) +\"\\n\")\n",
        "\n",
        "with open(\"HW2_Result1.txt\", \"w\") as f:\n",
        "    for s in dt_test_final1:\n",
        "        f.write(str(s) +\"\\n\")"
      ],
      "metadata": {
        "id": "eEfCNgvDXlnG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"HW2_Result5.txt\", \"w\") as f:\n",
        "    for s in dt_test_final_1:\n",
        "        f.write(str(s) +\"\\n\")"
      ],
      "metadata": {
        "id": "NxP1uoQQUVrq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers_list = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Naive Bayes : GaussianNB\": GaussianNB(),\n",
        "    \"Naive Bayes : BernoulliNB\": BernoulliNB()\n",
        "}\n",
        "\n",
        "classifiers_count = len(classifiers_list.keys())\n",
        "df_results = pd.DataFrame(data=np.zeros(shape=(classifiers_count,5)), columns = ['classifier', 'Recall', 'F1', 'Precision', 'Accuracy'])\n",
        "\n",
        "for c_name, classifier in classifiers_list.items():\n",
        "  classifier.fit(train_svd, y_train)\n",
        "  prediction = []\n",
        "  prediction = classifier.predict(test_svd)\n",
        "  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "  scores = cross_val_score(classifier, train_svd, y_train, cv=cv1)\n",
        "  print ('Classifier+Smote + SVD', c_name)\n",
        "  print ('Cross validation', scores)\n",
        "  print(classification_report(y_test,prediction))\n",
        "\n",
        "  classifier.fit(train_pca, y_train)\n",
        "  prediction1 = []\n",
        "  prediction1 = classifier.predict(test_pca)\n",
        "  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "  scores = cross_val_score(classifier, train_pca, y_train, cv=cv1)\n",
        "  print ('Classifier +Smote + PCA', c_name)\n",
        "  print ('Cross validation', scores)\n",
        "  print(classification_report(y_test,prediction1))\n",
        "\n",
        "  classifier.fit(train_sparse_sm_1, drug_active_sm_1)\n",
        "  prediction2 = []\n",
        "  prediction2 = classifier.predict(test_sparse_1)\n",
        "  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "  scores = cross_val_score(classifier,train_sparse_sm_1 , drug_active_sm_1, cv=cv1)\n",
        "  print ('Classifier + Chi', c_name)\n",
        "  print ('Cross validation', scores)\n",
        "  print(classification_report(y_test,prediction2))\n",
        "\n",
        "  classifier.fit(train_svd1, y_train)\n",
        "  prediction3 = []\n",
        "  prediction3 = classifier.predict(test_svd1)\n",
        "  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "  scores = cross_val_score(classifier, train_svd1, y_train, cv=cv1)\n",
        "  print ('Classifier + SVD', c_name)\n",
        "  print ('Cross validation', scores)\n",
        "  print(classification_report(y_test,prediction3))\n",
        "  \n",
        "  classifier.fit(train_pca1, y_train)\n",
        "  prediction4 = []\n",
        "  prediction4 = classifier.predict(test_pca1)\n",
        "  cv1 = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
        "  scores = cross_val_score(classifier, train_pca1, y_train, cv=cv1)\n",
        "  print ('Classifier + PCA', c_name)\n",
        "  print ('Cross validation', scores)\n",
        "  print(classification_report(y_test,prediction4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0-vt1Z-NVtD",
        "outputId": "5135ec54-c547-4f0c-b85b-3202a6718e24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier+Smote + SVD Decision Tree\n",
            "Cross validation [0.8671875 0.8984375 0.859375  0.859375  0.8515625]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96       146\n",
            "           1       1.00      0.21      0.35        14\n",
            "\n",
            "    accuracy                           0.93       160\n",
            "   macro avg       0.96      0.61      0.66       160\n",
            "weighted avg       0.94      0.93      0.91       160\n",
            "\n",
            "Classifier +Smote + PCA Decision Tree\n",
            "Cross validation [0.90625   0.90625   0.8671875 0.8828125 0.90625  ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       146\n",
            "           1       0.90      0.64      0.75        14\n",
            "\n",
            "    accuracy                           0.96       160\n",
            "   macro avg       0.93      0.82      0.86       160\n",
            "weighted avg       0.96      0.96      0.96       160\n",
            "\n",
            "Classifier + Chi Decision Tree\n",
            "Cross validation [0.76816609 0.71280277 0.73010381 0.73702422 0.76470588]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       146\n",
            "           1       0.75      0.43      0.55        14\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.85      0.71      0.76       160\n",
            "weighted avg       0.93      0.94      0.93       160\n",
            "\n",
            "Classifier + SVD Decision Tree\n",
            "Cross validation [0.84375   0.875     0.84375   0.8984375 0.8984375]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.89      0.93       146\n",
            "           1       0.36      0.64      0.46        14\n",
            "\n",
            "    accuracy                           0.87       160\n",
            "   macro avg       0.66      0.77      0.69       160\n",
            "weighted avg       0.91      0.87      0.88       160\n",
            "\n",
            "Classifier + PCA Decision Tree\n",
            "Cross validation [0.8984375 0.8828125 0.890625  0.8515625 0.8828125]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96       146\n",
            "           1       0.53      0.57      0.55        14\n",
            "\n",
            "    accuracy                           0.92       160\n",
            "   macro avg       0.75      0.76      0.75       160\n",
            "weighted avg       0.92      0.92      0.92       160\n",
            "\n",
            "Classifier+Smote + SVD Naive Bayes : GaussianNB\n",
            "Cross validation [0.765625  0.8515625 0.8046875 0.875     0.8828125]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       146\n",
            "           1       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           0.92       160\n",
            "   macro avg       0.96      0.54      0.55       160\n",
            "weighted avg       0.93      0.92      0.89       160\n",
            "\n",
            "Classifier +Smote + PCA Naive Bayes : GaussianNB\n",
            "Cross validation [0.7109375 0.7734375 0.734375  0.7890625 0.8125   ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.01      0.01       146\n",
            "           1       0.09      1.00      0.16        14\n",
            "\n",
            "    accuracy                           0.09       160\n",
            "   macro avg       0.54      0.50      0.09       160\n",
            "weighted avg       0.92      0.09      0.03       160\n",
            "\n",
            "Classifier + Chi Naive Bayes : GaussianNB\n",
            "Cross validation [0.72318339 0.60553633 0.6366782  0.6366782  0.6366782 ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91       146\n",
            "           1       0.38      1.00      0.55        14\n",
            "\n",
            "    accuracy                           0.86       160\n",
            "   macro avg       0.69      0.92      0.73       160\n",
            "weighted avg       0.95      0.86      0.88       160\n",
            "\n",
            "Classifier + SVD Naive Bayes : GaussianNB\n",
            "Cross validation [0.84375   0.890625  0.84375   0.8984375 0.8984375]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94       146\n",
            "           1       0.33      0.21      0.26        14\n",
            "\n",
            "    accuracy                           0.89       160\n",
            "   macro avg       0.63      0.59      0.60       160\n",
            "weighted avg       0.88      0.89      0.88       160\n",
            "\n",
            "Classifier + PCA Naive Bayes : GaussianNB\n",
            "Cross validation [0.6875    0.8203125 0.78125   0.8671875 0.8671875]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.86       146\n",
            "           1       0.10      0.21      0.14        14\n",
            "\n",
            "    accuracy                           0.76       160\n",
            "   macro avg       0.51      0.51      0.50       160\n",
            "weighted avg       0.84      0.76      0.80       160\n",
            "\n",
            "Classifier+Smote + SVD Naive Bayes : BernoulliNB\n",
            "Cross validation [0.8984375 0.953125  0.8671875 0.9140625 0.90625  ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       146\n",
            "           1       0.83      0.71      0.77        14\n",
            "\n",
            "    accuracy                           0.96       160\n",
            "   macro avg       0.90      0.85      0.87       160\n",
            "weighted avg       0.96      0.96      0.96       160\n",
            "\n",
            "Classifier +Smote + PCA Naive Bayes : BernoulliNB\n",
            "Cross validation [0.953125  0.9453125 0.890625  0.9140625 0.921875 ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       146\n",
            "           1       0.90      0.64      0.75        14\n",
            "\n",
            "    accuracy                           0.96       160\n",
            "   macro avg       0.93      0.82      0.86       160\n",
            "weighted avg       0.96      0.96      0.96       160\n",
            "\n",
            "Classifier + Chi Naive Bayes : BernoulliNB\n",
            "Cross validation [0.74394464 0.6816609  0.70588235 0.73010381 0.73702422]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97       146\n",
            "           1       0.63      0.86      0.73        14\n",
            "\n",
            "    accuracy                           0.94       160\n",
            "   macro avg       0.81      0.90      0.85       160\n",
            "weighted avg       0.95      0.94      0.95       160\n",
            "\n",
            "Classifier + SVD Naive Bayes : BernoulliNB\n",
            "Cross validation [0.9296875 0.953125  0.90625   0.9609375 0.9375   ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       146\n",
            "           1       0.80      0.57      0.67        14\n",
            "\n",
            "    accuracy                           0.95       160\n",
            "   macro avg       0.88      0.78      0.82       160\n",
            "weighted avg       0.95      0.95      0.95       160\n",
            "\n",
            "Classifier + PCA Naive Bayes : BernoulliNB\n",
            "Cross validation [0.9375    0.9609375 0.9140625 0.9453125 0.9296875]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       146\n",
            "           1       0.88      0.50      0.64        14\n",
            "\n",
            "    accuracy                           0.95       160\n",
            "   macro avg       0.91      0.75      0.80       160\n",
            "weighted avg       0.95      0.95      0.94       160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_final = BernoulliNB()\n",
        "print(train_sparse_sm_1.shape)\n",
        "print(test_sparse_final.shape)\n",
        "print(len(drug_active_sm_1)) \n",
        "naive_final.fit(train_svd1, y_train)\n",
        "naive_pred_final=naive_final.predict(sparse_test_svd)\n",
        "with open(\"HW2_Result_final_2.txt\", \"w\") as f:\n",
        "    for s in naive_pred_final:\n",
        "        f.write(str(s) +\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9GOdvsM4MZC",
        "outputId": "d0f4d8ce-5031-467e-971d-0408bb7c253a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1444, 300)\n",
            "(350, 300)\n",
            "1444\n"
          ]
        }
      ]
    }
  ]
}